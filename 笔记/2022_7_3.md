# 一、神经网络基础
#### 定义神经网络类的方法
```
#所有神经网络应为Moudle的子类
#例子
class MLP（nn.Moudle）:
    def __init__(self):
        super().__init__()  #继承Moudle的内部参数
        #定义特有的内部参数
        self.hidden = nn.Linear(20, 256)
        self.out  = nn.Linear(256, 10)
        
    def forward(self, X):   #构造函数中已调用
        return self.out(F.relu(self.hidden(X)))
        
 #使用神经网络类
 net=MLP()
 net(X)
 nn.Sequential()
```

#### 访问神经网络类的参数
```
#例子
net=nn.Sequential(nn.Linear(4,8), nn>relu(), nn.Linear(8, 1))
net[2].state_dict()  #输出nn.Linear(8,1)的weights和bias
net[2].bias     #输出nn.Linear(8,1)的bias，会被标注rqeuires_grad
net[2].bias.data    #输出输出nn.Linear(8,1)的bias的数据
net[2].weight.grad      #访问weight的梯度

#一次性访问所有参数
*[(name, param.shape) for name, param in net[0].named_parameters()]
#net[0]的所有参数
*[(name, param.shape) for name, param in net.named_parameters()]
#net的所有参数

net.state_dict()['2.bias'].data #根据变量名访问参数

```