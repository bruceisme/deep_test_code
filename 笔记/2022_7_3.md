# 一、神经网络基础
#### 定义神经网络类的方法
```
#所有神经网络应为Moudle的子类
#例子
class MLP（nn.Moudle）:
    def __init__(self):
        super().__init__()  #继承Moudle的内部参数
        #定义特有的内部参数
        self.hidden = nn.Linear(20, 256)
        self.out  = nn.Linear(256, 10)
       
    def forward(self, X):   #构造函数中已调用
        return self.out(F.relu(self.hidden(X)))
       
 #使用神经网络类
 net=MLP()
 net(X)
 nn.Sequential()
```
#### 访问神经网络类的参数
```
#例子
net=nn.Sequential(nn.Linear(4,8), nn>relu(), nn.Linear(8, 1))
net[2].state_dict()  #输出nn.Linear(8,1)的weights和bias
net[2].bias     #输出nn.Linear(8,1)的bias，会被标注rqeuires_grad
net[2].bias.data    #输出输出nn.Linear(8,1)的bias的数据
net[2].weight.grad      #访问weight的梯度
#一次性访问所有参数
*[(name, param.shape) for name, param in net[0].named_parameters()]
#net[0]的所有参数
*[(name, param.shape) for name, param in net.named_parameters()]
#net的所有参数
net.state_dict()['2.bias'].data #根据变量名访问参数
```
```
#!!!比较复杂
#嵌套快获得参数
#多层的块
def block1():
    retrun nn.Sequential(nn.Linear(4, 8), nn.Relu(), nn/Linear(8, 4), nn.Relu())
def block2():
    net = nn.Sequential()
    for i in range(4):
        net.add_moudle(f'block(i)', block1())
    return net
rgnet = nn.Sequential(block2(), nn.Linear(4,1))
 print(rgent)
```
模型结构
![861ab98088beaaf1a24fcbf481cc66cf.png](en-resource://database/614:1)

#### 初始化参数

```
def init_normal(m):
    if type(m) == nn.Linear:    #对线性模型初始化，为什么不对非线性初始化？不必要吗？（因为还没学到）
        nn.init.normal_(m.weight, mean=0, std=0.0)      #正态分布初始化weight
        #nn.init.constant_(m.weight, 1)#使用常数初始化权重
        nn.init.zeros_(m.bias)
net.apply(init_normal)          #对net中所有层使用init_normal函数

```
#### 共享权重
```
shared = nn.Linear(8,8)
net = nn.Sequential(nn.Linear(4, 8), nn.ReLU(), shared, nn.ReLU(), shared, nn.ReLU, nn.Linear(8, 1))
#这个网络中net[2]和net[4]就实现了共享参数
```

#### 读写文件
```
torch.save(x, 'file_name')      #在当前文件夹存储文件file_name
x2 = torch.load(x, 'file_name')      #在当前文件夹加载文件file_name

torch.save(net.state_dict(), ''params)  #将模型参数存进params里
clone=net()     #同样结构的模型
clone.load_state_dict(torch.load(params))       #加载模型参数

```
# GPU的使用（linux和colab）
```
!nvidia-smi     #查看gpu情况

import torch
from torch import nn
torch.device('cpu')     #默认使用cpu
torch.cuda.device('cuda')       #默认使用cuda/GPU:0号
torch.cuda.device('cuda:1')     #默认使用GPU：1号

torch.cuda.device_count()

#以下函数实现无GPU时运行代码
def try_gpu(i=0):
    if torch.cude.device_count()>=i+1:
        return torch.device(f'cuda:{i}')
    return torch.device('cpu')
def try_all_gpus():
    devices = [ torch.device(f'cuda:{i}') for i in range(torch.cuda.device_count())]
    return devices if devices else [torch.device('cpu')]
    
#使用
#数据在同一个gpu上可以进行计算
x=torch.ones(2,3, device=try_gpu())
net = net.to(device=try_gpu())
#确认模型参数存储在一个gpu上
net[0].weight,data,device

```
# 卷积
 ## 原理
 #### 全连接到卷积的两个原则

1.  平移不变性：识别器对像素特征的识别不会因为位置而改变
2.  局部性：寻找目标只需局部信息，不需要全局信息

#### 卷积层
![cc083d838e3c9a9a1e5f353a7e290b91.png](en-resource://database/616:2)
**卷积核大小是超参数**，控制局部性

```
#卷积底层代码
def corr2d(X, K):   #交叉相关运算
    h, w = K.shape
    Y = torch.zeros(X.shape[0]-h+1. X.shape[1]-w+1)
    for i in range(Y.shape[0])
        for j in range(Y.shape[1]):
            Y[i, j] = (X[i: i+h], j:j+w] *K).sum()
    return Y

#卷积层
class Conv2D(nn.Module):
    def __init__(self, kernel_size):
        super().__init__()
        self.weight = nn.Parameter(torch.rand(kernel_size))
       self.bias = nn.Parameter(torch.zeros(1))
    def forward(self, x):
        return corr2d(x, sele.weight)+self,bias
```

### 卷积填充与步辐（超参数）
#### 填充
在周围添加额外的行/列，以至于卷积后的特征不会太小
![cc083d838e3c9a9a1e5f353a7e290b91.png](en-resource://database/616:2)
![35260587e7cc7d8a41113fc1809450cf.png](en-resource://database/618:1)
![886db37f409fcc244c01b34758ca2855.png](en-resource://database/620:1)
**保证形状不变**
#### 步幅
指卷积核行列滑动的步长
对于较大的图片/特征，设置大的步幅可以减少计算量/参数量
给定了，卷积核大小k，特征大小n，填充长度p，对于步幅s
![27d789303e1f8b9ae48160751593a1df.png](en-resource://database/622:1)

```
import torch
from torch import nn

def comp_conv2d(conv2d, X):
    X = X.reshape((1, 1)+ X.shape)  #（1，1）加入一个通道和batch的维度
    Y = conv2d(X)
    return reshape(Y.shape[2:])
conc2d = nn.Conv2d(1,1, kernel_size=3, padding=1)   #8=8-3+1*2（pad=1）+1
#padding表示上下各填充一行，所以变成填充两行？输出=输入-卷积核+2*pad+1
X = torch.rand(size=(8, 8))
comp+conv2d(conv2d, X).shape

```
填充：输出=输入-卷积核+2* pad+1
步幅：输出=（输入-卷积核+2* pad+步幅）/步幅

### 通道（输出通道：超参数）

* 每个输入通道有独立的二维卷积核，所有通道的结果相加得到一个输出通道结果

* 每个输出通道有都立的三维卷积核，结果为4维（batch* 通道* 矩阵）

![f4008c761f51f70ec0fa997d0eb54574.png](en-resource://database/624:1)
![2ceeaeab28028da673dea17f6ef650ee.png](en-resource://database/626:1)

* 每个输出通道可识别不同的特征/模式

* 输入通道，识别并且组合特征/模式

#### 1* 1卷积层
**1* 1卷积用于通道融合**
如下，将3通道卷积变为2通道卷积
![ce5463b8aa4cde002e18865658a109a1.png](en-resource://database/628:1)
类似全连接层？
#### 二维卷积
![9fe357db1d99b02c9569c822d26c8c33.png](en-resource://database/630:1)


   ```
   #多输入的卷积运算
   #使用zip将对应通道的特征和卷积核打包，逐一卷积运算再将结果相加
def corr2d_multi_in(X, K):
    return sum(d2l.corr2d(x,k) for x, k in zip(X, K))

#多通道的输出
#对隐藏层的特征，使用多个卷积核，将结果堆叠，就得到多通道的输出
def corr2d_multi_out(X, K):
    return torch.stack([corr2d_multi_in(x,k) for k in K], 0)
K=torch.stack((K, K+1, K+2), 0)
```
### 池化
* 作用：缓解卷积对位置的敏感
* 输入通道=输出通道
* 可填充，可调步幅
#### （二维）最大池化
返回滑动窗口中的最大值
![4a263d9d1dbd88d263505d5729cdde57.png](en-resource://database/632:1)
#### 平均池化
返回滑动窗口中元素的平均值

## LeNet
输入（32x32）-->卷积(6x28x28)-->最大池化（6x14x14）-->卷积(16x10x10)-->最大池化(16x5x5)-->全连接（120）-->全连接（64）-->全连接(10)-->softmax()->>输出（10）

```
import
```