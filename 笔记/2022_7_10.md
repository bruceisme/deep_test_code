7.10
# DenseNet

* 与残差网络的差别在于，稠密连接的结果是拼接起来，而非直接相加，
* 残差连接一个残差结构相加一次，稠密连接结构拼接多次

* 这会导致后期的特征非常大，需要过渡层
![0bb4cf0193aad05e296f40c72511e72e.png](en-resource://database/680:1)

![e5cd2f0f7d7fb8691614ec1b188cadd3.png](en-resource://database/682:1)

# 深度学习硬件
![5cc52dfe265ea88cf74d66bf79dc18ec.png](en-resource://database/696:1)
数据并行：将小批量分成n块，每个GPU拿到完整参数技术以块数据的梯度，性能会更好
模型并行：将模型分成n块，每个gpu拿到一块模型技术它的前向和方向结构，通常用于模型达到单GPU放不下
## 多GPU训练
```
%matplotlib inline
import torch
from torch import nn
from torch.nn import functional as F
from d2l import torch as d2l

def get_params(params, device):
    new_params=[p.clone().to(device) for p in params]
    for p in new_params:
        p.requires_grad_()
   return new_params
   
new_params = get_params(params, d2l.try_gpu(0))
print(''b1 weight:", new_params[1])
print('b1 grad:' new_params[1].grad)


# allreduce函数将所有向量相加，并将结果广播给所有GPU
def allreduce(data):
    for i in range(1, len(data)):
        data[0][:]+=data[i].to(data[0].device)
    for i in range(1, len(data)):
        data[i]=data[0].to(data[i].devie)

data = [torch.ones((1, 2), device=d2l.try_gpu(i)) * (i + 1) for i in range(2)]
print('allreduce之前：\n', data[0], '\n', data[1])
allreduce(data)
print('allreduce之后：\n', data[0], '\n', data[1])


#将一个小批量数据均匀分布在多个GPU上
data=torch.arange(20).reshape(4,5)
devices = [torch.device('cude:0'), torch.device('cuda1')]
split=nn.parallel.scatter(data, devices)
print('input:' , data)
print('load into:', devices)
#将一个批次数据均匀分布到多个GPU上
def split_batch(X, YU, devices):
    assert X.shape[0] == Y.shape[0]
    return (nn.parallel.scatter(X, devices), nn.parallel.scatter(Y, devices))
    
 #多GPU训练
 def train_batch(X, y, device_params, devices, lr):
    X_shards, y_shards = split_batch(X, y, devices)
    ls = [loss(lenet(X_shard, device_W), y_shards).sum() for X.shards, y_shards, device_W in zip(X_shards, y_shards, device_params)]
    for l in ls:
        l.backward()
    with torch.no_grad():
        for i in range(len(device_params[0])):
            allreduce([device_params[c][i].grad for c in range(len(device)) ])
   for param in device_params:
        d2l.sgd(param, lr, X.shape[0])
```

# 数据增广/强
通过变形数据来获得多样性，是模型泛化性更好，更鲁棒
语音：在背景中加入各种噪音
图像：改变图片的颜色和形状
    1.切割，随机高宽比，随机大小，随机位置
    2.颜色，改变色调，饱和度，明亮度
```
#展示图片
d2l.set_figsize()
img=d2l.Image.open(...)
d2l.plt.imshow()

#对图片进行修改,并输出,aug:tochvision中图像变化方法，
def apply(img, aug, num_rows=2, num_cols=4, scale=1.5):
    Y = [aug(img) for _ in range(num_rows*num_cols)]
    d2l.show_images(Y, num_rows, num_cols, scale=scale)
    
#方法举例
#图片左右翻转
apply(img, torchvision.transforms.RandomHorizontalFlip())
#图片上下翻转
apply(img, torchvision.transforms.RandomVerticalFlip())
#图片随机裁剪
shape_aug = torchvision.transforms.RandomResizedCrop(
    (200, 200), scale=(0.1, 1), ratio=(0.5, 2))
apply(img, shape_aug)

#图片修改亮度，brightness
apply(img, torchvision.transforms.ColorJitter(
    brightness=0.5, contrast=0, saturation=0, hue=0))
    
#图片修改色调，hue
apply(img, torchvision.transforms.ColorJitter(
    brightness=0, contrast=0, saturation=0, hue=0.5))
#contrast 对比度。saturation 饱和度。
```
# 微调
## 理论
一般神经网络（以分类任务为例）可以分为1：特征提取和2：线性分类器

微调指使用在源数据集（大型）上预训练的神经网络模型的特征提取层，拼接新的线性分类器，在新的数据集上训练，输出层（线性分类器）随机初始化开始训练，特征提取层微调

通常速度更快，精度更好

#### 微调训练
目标数据集上的正常训练任务，但使用更强的正则化（更小的学习率更少的数据迭代）

微调数据集：源数据集通常要大于目标数据集，能达到更好的效果

#### 重用分类器权重

源数据集中可能也有目标数据中的部分标号，可以使用预训练模型分类器中对应的向量来做初始化

#### 固定某些层
神经网络通常学习有层次的特征表示，低层次的特征更加通用（前面），高层次的特征更跟数据集有关--》可以固定底部一些层（前面几层）的参数，不参与更新